{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7fcf94f-81bb-42e4-9b18-de373c7fbe6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pandas\n",
    "# pip install numpy\n",
    "# !pip install transformers -U\n",
    "# pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "# pip install accelerate -U\n",
    "# pip install transformers[torch]\n",
    "# pip install accelerate>=0.21.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "127dc4f3-8bb8-47c0-93d2-edc1b1916bfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bBelgian cardinals prevent priests to be in a ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Majority of Russians and Americans View Each O...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mr. Koistinen joins from Nokia Siemens Network...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Blatter to stand again for footballs top job</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brazils Army Moves To Protect Indigenous Aw Tr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline  Label\n",
       "0  bBelgian cardinals prevent priests to be in a ...      0\n",
       "1  Majority of Russians and Americans View Each O...      0\n",
       "2  Mr. Koistinen joins from Nokia Siemens Network...      0\n",
       "3       Blatter to stand again for footballs top job      0\n",
       "4  Brazils Army Moves To Protect Indigenous Aw Tr...      1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(r\"D:\\FYP\\Final Model Training\\Data Set\\Final_data_set_shuffle_for_model.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d2d1bb9-a46e-4556-b41b-3bd17974982f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "1    62874\n",
       "0    61492\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Label\"].value_counts()\n",
    "# data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7be8526b-1778-4402-9a4d-ce9de8bcec7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "1    62874\n",
       "0    61492\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[['Headline','Label']]\n",
    "data.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fdc8f52-28f2-4534-aa31-67dbf0cb9944",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score\n",
    "import torch\n",
    "from transformers import TrainingArguments,Trainer\n",
    "from transformers import BertTokenizer,BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d16f4f6-05b5-4322-a907-61620a2b595c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('google-bert/bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('google-bert/bert-base-uncased',num_labels=2)\n",
    "model = model.to('cpu') # if CPU is available\n",
    "# model = model.to('cuda') # if GPU is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f921fb9-6556-4524-af29-d6d822d89469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 7592, 2088, 102, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2026, 2171, 2003, 29393, 7911, 2078, 8670, 10023, 10711, 2099, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# padding  = Ture Make all the list at same list add extra 0 to the list\n",
    "# truncation = Ture which wil be truncate any text which has more than 512 words. Which maximum context size is the maximun amount of words a model can accept  \n",
    "# return_tensors=True Convert normal python list to the tensorflow tensor\n",
    "sample_data = [\"Hello World\",\"My name is Arsalan Bakhtiar\"]\n",
    "tokenizer(sample_data ,padding = True , truncation= True , max_length= 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f46082f2-a07c-44d3-a8c0-b81d1da92ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(data['Headline'])\n",
    "y = list(data['Label'])\n",
    "X_train,X_val,y_train,y_val = train_test_split(X,y,test_size = 0.2,stratify=y)\n",
    "X_train_tokenized = tokenizer(X_train, padding=True, truncation=True, max_length= 512)\n",
    "X_val_tokenized = tokenizer(X_val, padding=True, truncation=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a8f811d-5a69-44cc-99c1-71a00772ae32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99492, 24874)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train),len(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7c19892-6cd7-4355-9507-2e6f3a1b5180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tokenized.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9276b95-bb15-4a8b-8136-01b7764ead77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 4518, 3863, 2713, 9800, 11387, 14526, 14840, 2624, 9626, 2038, 2405, 2049, 3296, 3189, 1998, 3361, 8635, 2005, 2230, 1998, 2049, 2034, 5971, 5368, 3189, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_tokenized['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a57fdf3-dd7c-4469-afc6-cd7f2b805640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 7592, 2088, 102, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2026, 2171, 2003, 29393, 7911, 2078, 8670, 10023, 10711, 2099, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data = [\"Hello World\",\"My name is Arsalan Bakhtiar\"]\n",
    "tokenizer(sample_data ,padding = True , truncation= True , max_length= 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "047ab224-e46b-4c0d-8ae7-57dadbd0ef0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create torch dataset\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels=None):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        if self.labels:\n",
    "            item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a48b919d-4f77-4e0e-b7fa-e6e718fc0ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(X_train_tokenized, y_train)\n",
    "val_dataset = Dataset(X_val_tokenized, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69fe0b89-7447-424a-9911-d8cd6ec05de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93eb1e0c-d005-4787-86ce-bc44f911678e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    print(type(p))\n",
    "    pred, labels = p\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "\n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
    "    recall = recall_score(y_true=labels, y_pred=pred)\n",
    "    precision = precision_score(y_true=labels, y_pred=pred)\n",
    "    f1 = f1_score(y_true=labels, y_pred=pred)\n",
    "\n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ec85cc2-04ce-490e-af47-86099f56e696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Trainer\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"output\",\n",
    "    num_train_epochs = 4,\n",
    "    per_device_train_batch_size=8\n",
    "\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ded7fe5-5c44-4ef8-8f82-dfdf0e2a2995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='280' max='49748' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  280/49748 40:34 < 120:21:05, 0.11 it/s, Epoch 0.02/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6907c3-6283-487d-9d65-cf871261a6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6360369c-70a4-477e-854d-5f8106d81f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8591da0-7ec0-4223-8cc7-0955f9a71ab6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845f1d64-5890-4c08-b4c7-7aaca34a60e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"In the third quarter of 2010 , net sales increased by 5.2 % to EUR 205.5 mn , and operating profit by 34.9 % to EUR 23.5 mn\"\n",
    "inputs = tokenizer(text,padding = True, truncation = True, return_tensors='pt').to('cpu')\n",
    "outputs = model(**inputs)\n",
    "# print(outputs)\n",
    "predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "# print(predictions)\n",
    "predictions = predictions.cpu().detach().numpy()\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac161af-3549-4d10-8a83-cff68ed5188d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"google-bert/bert-base-uncased-512-4 epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b832fea-0137-4019-8393-cadd0268d30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer,BertForSequenceClassification\n",
    "model_2 = BertForSequenceClassification.from_pretrained(\"Fine_tuned_model\")\n",
    "model_2.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "891e2135-503e-4ad8-b9de-2e5ce2f98e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01005797 0.98994195]]\n",
      "X : 0.010057974\n",
      "Y : 0.98994195\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# text = \"That was good point\"\n",
    "text = \"For the last quarter of 2010 , Componenta 's net sales doubled to EUR131m from EUR76m for the same period a year earlier , while it moved to a zero pre-tax profit from a pre-tax loss of EUR7m \"\n",
    "tokenizer = BertTokenizer.from_pretrained('google-bert/bert-base-uncased')\n",
    "inputs = tokenizer(text,padding = True, truncation = True, return_tensors='pt').to('cpu')\n",
    "outputs = model_2(**inputs)\n",
    "predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "predictions = predictions.cpu().detach().numpy()\n",
    "predictions\n",
    "x = predictions[0, 0]\n",
    "y = predictions[0, 1]\n",
    "print(predictions)\n",
    "print(\"X :\",x)\n",
    "print(\"Y :\",y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290dcac8-84d4-4f20-97a9-9d4652cede31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first one is 0 and second 1 is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85ea456e-49a4-4a19-b277-6a83e381a3b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01005797 0.98994195]]\n",
      "X : 0.010057974\n",
      "Y : 0.98994195\n"
     ]
    }
   ],
   "source": [
    "print(predictions)\n",
    "print(\"X :\",x)\n",
    "print(\"Y :\",y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17109e6-ebe9-4570-ba2f-881dc6653f46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c410899-a99a-4a74-946b-376d7bce9354",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b18661-0e15-4e59-8072-24d3cf8c9830",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFAutoModel,\n",
    "                         AutoTokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45053c0-dc29-43b9-b305-e4b9074d5fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the model form the internet\n",
    "model = TFAutoModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca36bf4-784f-46c8-8289-0cae5adc125f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer\n",
    "tokenizer = TFAutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517b75e6-5d64-4574-a5c4-9d76e762abe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding  = Ture Make all the list at same list add extra 0 to the list\n",
    "# truncation = Ture which wil be truncate any text which has more than 512 words. Which maximum context size is the maximun amount of words a model can accept  \n",
    "# return_tensors=True Convert normal python list to the tensorflow tensor\n",
    "inputs = tokenizer(\"Hello World\",'Hi how are',padding = True, truncation = True, return_tensors = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf7205b-bc68-419b-b496-3350060501a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call bert to train the model\n",
    "output = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6c0692-a930-4cd2-9a12-b86fb8270fc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a93c09-43f8-438d-a7ec-c776dafa0f47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b785db4-4aee-49fb-b42a-6ef2e2abf4b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44347e64-f8b3-442c-83e1-160e3fdf8d43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca1e310-39ce-43a7-844a-323afbe981fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30791b31-0b27-4cb6-9458-8fee188b52db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36130aba-c82d-48c5-8db5-303151db16cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce1022d-15a6-4cdb-93ea-13bf4224c963",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a561942-a63a-4ae8-8424-e7f7c34fc0d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
